---
title: "Trees"
date: 2021-04-14
categories:
  - blog
tags:
  - algorithm
  - leetcode
  - traversal
  - DFS
  - BFS
  - summary
---

1. [两类二叉树解题的思维模式][二叉树]:    
    1. 「遍历」的思维模式 (对应回溯算法核心框架)
        * 是否可以通过遍历一遍二叉树得到答案？如果可以，用一个 `traverse` 函数配合外部变量来实现，
    2. 「分解问题」的思维模式 (对应动态规划核心框架)
        * 是否可以定义一个递归函数，通过子问题（子树）的答案推导出原问题的答案？如果可以，写出这个递归函数的定义，并充分利用这个函数的返回值
2. 无论使用哪种思维模式，你都需要思考：
    1. 如果单独抽出一个二叉树节点，它需要做什么事情？需要在什么时候（前/中/后序位置）做？其他的节点不用你操心，递归函数会帮你在所有节点上执行相同的操作。
3. 二叉树的重要性
    1. 如果你告诉我，快速排序就是个二叉树的前序遍历，归并排序就是个二叉树的后序遍历，那么我就知道你是个算法高手了。
    2. 二叉树的算法思想的运用广泛，甚至可以说，只要涉及递归，都可以抽象成二叉树的问题
4. 深入理解前中后序
    1. `traverse` 其实就是一个能够遍历二叉树所有节点的一个函数，和你遍历数组或者链表本质上没有区别. 把 `traverse` 理解成在二叉树上游走的一个指针.
        * 单链表和数组的遍历可以是迭代的，也可以是递归的，二叉树这种结构无非就是二叉链表，由于没办法简单改写成迭代形式，所以一般说二叉树的遍历框架都是指递归的形式。
        * 只要是递归形式的遍历，都可以有前序位置和后序位置，分别在递归之前和递归之后。
    2. 前中后序是遍历二叉树过程中处理每一个节点的三个特殊时间点，绝不仅仅是三个顺序不同的 List：
        * 前序位置的代码在刚刚进入一个二叉树节点的时候执行；
        * 后序位置的代码在将要离开一个二叉树节点的时候执行；
        * 中序位置的代码在一个二叉树节点左子树都遍历完，即将开始遍历右子树的时候执行。
    3. 你可以发现每个节点都有「唯一」属于自己的前中后序位置，所以我说前中后序遍历是遍历二叉树过程中处理每一个节点的三个特殊时间点。
        * 这里你也可以理解为什么多叉树没有中序位置，因为二叉树的每个节点只会进行唯一一次左子树切换右子树，而多叉树节点可能有很多子节点，会多次切换子树去遍历，所以多叉树节点没有「唯一」的中序遍历位置。
5. 二叉树的所有问题，就是让你在前中后序位置注入巧妙的代码逻辑，去达到自己的目的，你只需要单独思考每一个节点应该做什么，其他的不用你管，抛给二叉树遍历框架，递归会在所有节点上做相同的操作。
6. 后序位置的特殊之处
    1. 中序位置主要用在 BST 场景中，你完全可以把 BST 的中序遍历认为是遍历有序数组。
    2. 前序位置的代码执行是自顶向下的，而后序位置的代码执行是自底向上的.
    3. 但这里面大有玄妙，意味着前序位置的代码只能从函数参数中获取父节点传递来的数据，而后序位置的代码不仅可以获取参数数据，还可以获取到子树通过函数返回值传递回来的数据。
        * 那么换句话说，一旦你发现题目和子树有关，那大概率要给函数设置合理的定义和返回值，在后序位置写代码了。
7. 二叉树遍历框架
    ```
    void traverse(TreeNode root) { 
        if (root == null) {
            return;
        }
        // 前序位置
        traverse(root.left);
        // 中序位置
        traverse(root.right);
        // 后序位置
    }
    ```

1. Traversal:
    1. When to use DFS and when to use BFS?
        1. BFS: Searching for **shortest path**
            * If using DFS, it can be a very wrong (LC909) when a later node can jump back to node in front of the current one.
    2. Depth-First-Search (DFS)
        1. Recursion method
        1. preorder
            * 但你是否能够用「分解问题」的思路，来计算前序遍历的结果？[这个算法的复杂度不好把控，比较依赖语言特性][二叉树]
            * [The property of preorder traversal array][C++ easy to understand solution with thought process and detailed explanation]: 
                * We print left child’s value of current node all the way until we reached a leaf node (you will see numbers decreasing), then we start printing the value of a node (let it be `rc`) which is the right child of one of the nodes (let it be node `p`) we already traversed. When do you know it's a right child node's value? It's when you see a value greater than the last one. Also, till here we know, all the nodes in `p`’s left subtree have been read in the serialized array, and this property is maintained: `left subtree's values < p value < rc value`.
                * Since all the nodes whose value is smaller than `p` are already read, all the nodes’ value to be read after should have greater value than `p` value, so `p` value becomes the lower bound for any upcoming node. `p value < upcoming value in array`. Otherwise, it’s not valid preorder traversal.
            * Stack method
                * Push root into stack.
                * While stack is not empty:
                    * Pop out a node from stack and update the current number.
                    * If the node is a leaf, update root-to-leaf sum.
                    * Push right and left child nodes into stack.
                * You can usually put other state values together with the node into the stack to compute target value
                ```
                stack = [root]
                res = []
                while stack:
                    current = stack.pop()
                    if current:
                        res.append(current.val)
                        stack.append(current.right)
                        stack.append(current.left)            
                ```
            * Morris method: Here the idea is to go down from the node to its predecessor, and each predecessor will be visited twice. For this go one step left if possible and then always right till the end. When we visit a leaf (node's predecessor) first time, it has a zero right child, so we update output and establish the pseudo link predecessor.right = root to mark the fact the predecessor is visited. When we visit the same predecessor the second time, it already points to the current node, thus we remove pseudo link and move right to the next node.
                * Does it have left child?
                    * Yes, go left and then right until None or meet current node
                        * You meet None, output current node, set predecessor.right = current_node
                            * New node is current_node.left
                        * You meet current node, delete linke
                            * New node is current_node.right
                    * No, Add node to output
                        * New node is current_node.right

        2. inorder
            * Recursion
            ```
            def inorder(r: TreeNode) -> List[int]:
                return inorder(r.left) + [r.val] + inorder(r.right) if r else []

            def traverse (TreeNode root):
                if (root == null)
                    return;
                traverse(root.left)
                // Do some thing
                traverse(root.right)
            ```

            * Use stack, push all left children to the stack and then start pop. N.B. The order of `stack.pop()` is the same order as in-order traversal
            ```
            stack = []        
            inorder = []
            current = root            
            while stack or current:
                while current:
                    stack.append(current)
                    current = current.left                
                current = stack.pop()                    
                inorder.append(current)
                current = current.right
            ```
            * Morris Traversal: `O(1)` space complexity
                * How one could know that the left subtree is already done if no additional memory is allowed?
                * The idea of Morris algorithm is to set the temporary link between the node and its predecessor: `predecessor.right = root`. 
                * So one starts from the node, computes its predecessor and verifies if the link is present. 
                    * If there is left child, predecessor is one step left and then right till you can
                    * If there is no left child, predecessor is itself
                * There is no link? Set it and go to the left subtree. There is a link? Break it and go to the right subtree.
                * There is one small issue to deal with : what if there is no left child, i.e. there is no left subtree? Then go straightforward to the right subtree.
        3. postorder
            1. Two stacks method
            ```
            stack1 = [root]
            stack2 = []
            while stack1:
                current = stack1.pop()
                if current:                
                    stack1.append(current.left)
                    stack1.append(current.right)                        
                    stack2.append(current.val)
            return stack2[::-1]
            ```
            2. [One stack method][Iterative postorder traversal of a binary tree with a single stack, how to approach the problem?]
            ```
            if not root:
                return []
            
            res = []
            new, left_done, right_done = 0, 1, 2
            stack = [[root, new]]
            while stack:
                node, state = stack[-1]
                if state == right_done:
                    stack.pop()
                    res.append(node.val)
                else:
                    stack[-1][1] += 1
                    nxt = [node.left, node.right][state]
                    if nxt:
                        stack.append([nxt, new])                
            return res
            ```

            3. Another one stack solution: It pushes the right-hand tree onto the stack before the current node. Then later, when you return to the current node, having taken it from the stack, you can detect the case where you still need to process the right-hand side because the top of the stack will have the right-hand node. In that case you swap the top of the stack with the current node and continue from there; you'll later return to the same place and will no longer have that right-hand side node on the top of the stack so you can print:
            ```
            current = root
            stack = []
            res = []
            while current or stack:
                while current:
                    if current.right:
                        stack.append(current.right)
                    stack.append(current)
                    current = current.left
                
                current = stack.pop()
                if stack and current.right == stack[-1]:
                    current, stack[-1] = stack[-1], current
                else:
                    res.append(current.val)
                    current = None            
            return res
            ```

        4. DFS and Union Find (LC721)
        5. If you need to differentiate subtrees in a tree, you can use the string representation of each subtree as key (Note, the key increases with the size of tree, and thus is `O(n)` in worst case). So in DFS recursion, you can re-use previously visited subtrees.
        6. Iterative method: use stack
    3. Breadth-First-Search (BFS)
        1. Usually we keep a `visited` set to avoid repetive visiting of the same node
            * By the way, normally for BFS, the main space complexity lies in the process rather than the initialization. For instance, for a BFS traversal in a tree, at any given moment, the queue would hold no more than 2 levels of tree nodes. Therefore, the space complexity of BFS traversal in a tree would depend on the width of the input tree.
        2. BFS is usually used to find the shortest path
            * You can put the distance together with key into the deque
            * Keeping track of how many cells at each distance are on the queue
            * If you can overwrite the input, you can put the distance onto the original input
            * Starting a new collection for each distance as there are at most two unique distances in the queue at any one time.
            * `A*` algorithm (Advanced), see [Shortest Path in Binary Matrix][LC1091]: 
                * Intuition: At certain point, one of the two cells to explore seemed far more promising than the other. We want to modify the algorithm to prioritize promising paths over not so promising paths. To do this, we need to come up with a heuristic that, given a potential option, it measures how much "promise" that option has. Then we prioritize the options (exploring cells) with the highest "promise". In the previous approaches, we were actually doing this: our heuristic was simply distance traveled so far. But we can do better than that!
                * Instead, we're going to score them based on distance traveled so far plus our most optimistic estimate of how many more steps it would take to get to the destination cell from there. 
                * Problem: We have made the wrong assumption that we can take the most promising cell and assume that the best possible distance to all of its neighbors is 1 more. But this is not always the case. 
                * To solve this, we simply need to remove the bad assumption; we shouldn't conclude that the first path we discover into a cell is the best one. Instead, we should keep track of all the options and then choose the best one when we get to it.
                * Suppose an estimate of a cell represents the shortest possible path we could get from the top-left to the bottom-right if we were to go through that cell.
                * A "child" cell could never have a lower estimate () than a "parent" cell. If it did, this would mean that the "parent" cell's estimate was not the lowest possible; we would have just found a way for it to be lower, which is contradictory. So when a "parent" cell puts options to get to "child" cells onto the priority queue, the estimates for these options are never less than the estimate for the parent. If the parent's estimate is `x`, then it will only put options with estimates of `x` or higher onto the priority queue.
                * The key implication of this is that if there is a way to get to a cell that assigns it an estimate of x, then we know that we won't inadvertently accept a higher estimate, only to later discard the x estimate like our first attempt at this algorithm might have done. Estimates of x can only be put onto the queue by cells with an estimate of x or lower. So by definition, we know that once we're taking off options with an estimate of x + 1, we have already exhausted all possible ways of getting estimates of x. Each estimate value "tier" has all of its members identified before and during the processing of that "tier"
                * No cell can have an estimate lower than that of the top-left cell.
                * For A*, we are assigning the most optimistic possible estimate to each cell and then exploring cells in non-decreasing order of these estimates. We'll keep track of potential options into cells that we haven't yet visited using a priority queue. 
                * The key idea is that the estimates for any given path from the top-left to bottom-right cell are non-decreasing;
                * This is `O(NlogN)` complexity if we don't limit the size of priority queue. The `N` is the total number of cells.
        3. Implementation 1: queue (single queue if you use its size, double queues otherwise)
        4. Implementation 2: Recursion, N.B. the visit order here is actually DFS, but the output order is BFS.
        ```
        levels = [] #The array to save the level traversal
        if not root:
            return levels
        
        def helper(node, level):
            # start the current level
            if len(levels) == level:
                levels.append([])

            # append the current node value
            levels[level].append(node.val)

            # process child nodes for the next level
            if node.left:
                helper(node.left, level + 1)
            if node.right:
                helper(node.right, level + 1)
            
        helper(root, 0)
        ```

    3. Recover Tree from different orders
        1. Recover Binary Search Tree            
            * [Serialize in preorder and deserialize using stack or recursive method using current value as lower/upper bound][LeetCode 449]
            * Serialize in postorder and deserialize recursively
        2. One can also serialize using BFS, like LeetCode does for the tree structure.
    4. Construct Binary Tree from Inorder and Postorder Traversal or Preorder and Inorder Traversal
        1. Use recursion. 
            * To save the time of finding root in the inorder array, you can build a hashmap from value to position. `O(n)`
            * To avoid using the indexes from postorder/preorder array, you can intelligently build right/left tree first, so to use one index to update the root in postorder/preorder array.
        2. Iterative method: 
            1. Keep pushing the nodes from the preorder into a stack (and keep making the tree by adding nodes to the left of the previous node) until the top of the stack matches the inorder.
            2. At this point, pop the top of the stack until the top does not equal inorder (keep a flag to note that you have made a pop).
            3. Repeat 1 and 2 until preorder is empty. The key point is that whenever the flag is set, insert a node to the right and reset the flag.
        3. Problems
            * [LC106. Construct Binary Tree from Inorder and Postorder Traversal][LC106. Construct Binary Tree from Inorder and Postorder Traversal]
            * [LC105. Construct Binary Tree from Preorder and Inorder Traversal][LC105. Construct Binary Tree from Preorder and Inorder Traversal]
    5. Construct Binary Search Tree from Inorder Traversal
        1. Use recursion
        2. Recursion method by simulating inorder traversal as we move along the sorted array

        ```
        # Recursively form a BST out of linked list from l --> r
        def convert(l, r):
            nonlocal head            
            if l > r: # Invalid case
                return None

            mid = (l + r) // 2
            # Recursively form the left half
            left = convert(l, mid - 1)

            # Once left half is traversed, process the current node
            node = TreeNode(head.val)   
            node.left = left

            # Maintain the invariance: whenever we are done building the left half of the BST, the head  # pointer in the linked list will point to the root node or the middle node (which becomes   # the root). So, we simply use the current value pointed to by head as the root node and     # progress the head node by once i.e. head = head.next

            head = head.next

            # Recurse on the right hand side and form BST out of them
            node.right = convert(mid + 1, r)
            return node

        convert(0, size - 1)        
        ```
    6. Binary Search Tree
        1. FACT: Inorder traversal of BST is an array sorted in the ascending order: `inorder = sorted(preorder)`.
        2. FACT: inorder + postorder or inorder + preorder are both unique identifiers of whatever binary tree.
        3. Inorder traversal is not a unique identifier of BST. At the same time both preorder and postorder traversals are unique identifiers of BST.
        4. How to handle duplicates
        5. The complexity of insert/delete in BST is `O(log N)`, search is also `O(log N)`. If there are frequrent insert/delete/search, one can use double linked list to store the numbers and speedup the operations.

5. [Serialize and DeSerialize Trees][Serialize Tree]
    1. If given Tree is Binary Search Tree? 
        If the given Binary Tree is Binary Search Tree, we can store it by either storing preorder or postorder traversal. In case of Binary Search Trees, only preorder or postorder traversal is sufficient to store structure information. 
    2. If given Binary Tree is Complete Tree? 
        A Binary Tree is complete if all levels are completely filled except possibly the last level and all nodes of last level are as left as possible (Binary Heaps are complete Binary Tree). For a complete Binary Tree, level order traversal is sufficient to store the tree. We know that the first node is root, next two nodes are nodes of next level, next four nodes are nodes of 2nd level and so on. 
    3. If given Binary Tree is Full Tree? 
        A full Binary is a Binary Tree where every node has either 0 or 2 children. It is easy to serialize such trees as every internal node has 2 children. We can simply store preorder traversal and store a bit with every node to indicate whether the node is an internal node or a leaf node.

    4. How to store a general Binary Tree? 
        A simple solution is to store both Inorder and Preorder traversals. This solution requires space twice the size of Binary Tree. We can save space by storing Preorder traversal and a marker for NULL pointers. 
        ```
            If we use -1 as NULL
            Input:
             20
            /   \
           8     22 
        Output: 20 8 -1 -1 22 -1 -1 
        ```
    5. How much extra space is required in above solution? 
        If there are n keys, then the above solution requires n+1 markers which may be better than simple solution (storing keys twice) in situations where keys are big or keys have big data items associated with them.
    6. Can we optimize it further?     
        The above solution can be optimized in many ways. If we take a closer look at above serialized trees, we can observe that all leaf nodes require two markers. One simple optimization is to store a separate bit with every node to indicate that the node is internal or external. This way we don’t have to store two markers with every leaf node as leaves can be identified by extra bit. We still need marker for internal nodes with one child.
    7. [Serialize N-ary tree][LC428. Serialize and Deserialize N-ary Tree]
        * Serialize: 
            * If permissible, we represent each number as a unicode character, which helps to avoid conversion between integer and strings (and using deliminator and doing split during deserialization). It won't work with negative numbers, and Won't work if the numbers are > 65536.            
            * Otherwise, we have to use a deliminator to separate different numbers in the string format, e.g. is `234` `2` and `34` or `23` and `4`?
            * We can assign a unique ID to each node to differentiate them.
            * We use this format to represent each ID: currnetNodeId + currentNodeValue + parentNodeId, so each node is represented by 3 chars
            * To get rid of usage of unique ID, we can use this format: currentNodeValue + numberOfChildren.
            * Or we add a sentinel value when all the children have been added to the final string. (DFS)
            * Use DFS or BFS to generate the sequence of nodes
            * BFS: 
                * Which node has what children since a level can contain a lot nodes and we need to know the parent of each one of them.
                * Second, and the more common information is the switch from one level to another. We need to add this information somehow in the string which helps the deserializer know that a level has finished and a new one has begun.


        * Deserialize: 
            * Use an index to iterate the string
            * We build a map from node Id to its value and parent Id.
            * You can use recursive method to deserialize


6. Balanced Binary Search Tree
    1. The search/add/remove operations are all bounded by a logarithmic complexity in terms of the number of elements in the tree. 
    2. Make an imbalanced BST to a balanced BST
        * Produce inorder array then use middle element as root, and recursively convert

7. Find a shortest path related to a node within a Tree
    1. Convert the tree to a graph using DFS (note it's undirected graph here), then use BFS to find the shortest path to a vertex

8. Unique Binary Search Trees (BST)
    1. The main computations are to construct all possible trees with a given root, that is actually Catalan number `G_n`. If you have a tree with branching of `b` and max depth of `m`, the total number of nodes in this tree in worst case: `1 + b + b^2 + ... + b^(m-1)`, which is a sum of geometric sequence: `(b^m-1)/(b-1)`. So you can say that time complexity is `O(b^m)`. For the case here it will be `O(n*2^n)`. 
    2. Problems
        * [LC95. Unique Binary Search Trees II][LC95. Unique Binary Search Trees II]

9. Check if a BST is valid
    1. Recursion, specify an upper and lower limit for the current tree
    2. Use stack (DFS).    
    3. Use In-order traversal to check if the nodes are in order

10. [Flatten Binary Tree to Linked List][LC114. Flatten Binary Tree to Linked List]
    1. Use recursive method
    2. Use stack, you can add state for each node, e.g. 'START' and 'END', can give you four states to work with.
    3. Modified Morris traversal to get `O(1)`: we will have to come up with a `greedy` way that will be costlier in terms of time, but will be space efficient in achieving the same results.
        * For a current node, we will check if it has a left child or not. If it does, we will find the last node in the rightmost branch of the subtree rooted at this left child. Once we find this "rightmost" node (keep moving on right until we can't), we will hook it up with the right child of the current node.
        * We set the right child of the current node to the current left child

11. Find the lowest common ancestor
    1. 
    2. Problems
        * [LC236. Lowest Common Ancestor of a Binary Tree][LC236. Lowest Common Ancestor of a Binary Tree]

12. [Verify Preorder Sequence in Binary Search Tree][LC255. Verify Preorder Sequence in Binary Search Tree]
    1. How to control the time complexity? i.e. avoid going through each element to get the boundary of left/right children.
        * Use stack
        * Use recursion: it's interesting to see how the recursion is applied here. 

13. Check if preorder is valid
    1. Binary tree could be considered as a number of slots to fulfill. At the start there is just one slot available for a number or null node. Both number and null node take one slot to be placed. For the null node the story ends up here, whereas the number will add into the tree two slots for the child nodes. Each child node could be, again, a number or a null.
        * The idea is straightforward : take the nodes one by one from preorder traversal, and compute the number of available slots. If at the end all available slots are used up, the preorder traversal represents the valid serialization.
    2. The key here is, when you see two consecutive "#" characters on stack, pop both of them and replace the topmost element on the stack with "#" (you are shrinking tree's child to null because you already process the child and all it's children). If there is only one # on stack at the end of the string then return True else return False.



    
Resources:
* [827. Making A Large Island][LeetCode Link]


[LeetCode Link]: https://leetcode.com/problems/making-a-large-island/
[LeetCode 449]: https://leetcode.com/problems/serialize-and-deserialize-bst/
[LC1091]: https://leetcode.com/problems/shortest-path-in-binary-matrix/solution/
[Serialize Tree]: https://www.geeksforgeeks.org/serialize-deserialize-binary-tree/
[LC428. Serialize and Deserialize N-ary Tree]: https://leetcode.com/problems/serialize-and-deserialize-n-ary-tree/
[LC95. Unique Binary Search Trees II]: https://leetcode.com/problems/unique-binary-search-trees-ii/
[LC105. Construct Binary Tree from Preorder and Inorder Traversal]: https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/
[LC106. Construct Binary Tree from Inorder and Postorder Traversal]: https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/
[LC114. Flatten Binary Tree to Linked List]: https://leetcode.com/problems/flatten-binary-tree-to-linked-list/
[Iterative postorder traversal of a binary tree with a single stack, how to approach the problem?]: https://stackoverflow.com/questions/54635756/iterative-postorder-traversal-of-a-binary-tree-with-a-single-stack-how-to-appro
[LC236. Lowest Common Ancestor of a Binary Tree]: https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/
[LC255. Verify Preorder Sequence in Binary Search Tree]: https://leetcode.com/problems/verify-preorder-sequence-in-binary-search-tree/
[C++ easy to understand solution with thought process and detailed explanation]: https://leetcode.com/problems/verify-preorder-sequence-in-binary-search-tree/discuss/68185/C++-easy-to-understand-solution-with-thought-process-and-detailed-explanation
[二叉树]: https://labuladong.github.io/algo/1/7/